---
title: "Estimation"
output:
  html_notebook:
    toc: true
    toc_float: true
---



```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(emphasis) # Load the Emphasis package


# Install and load the required packages
if (!requireNamespace("ape", quietly = TRUE)) {
  install.packages("ape")
}
library(ape)

```



## Estimating the likelihood 


Phylogenies that are derived from molecular data (e.g. DNA sequences) are, however, not full trees, as they do not contain the extinct species. The likelihood for an observed tree can be written in terms of the likelihood of compatible full trees. In principle, this is simply the integration over all possible full trees that are compatible with the observed tree $x_{obs}$:

\begin{equation}
	f(x_{obs}|\theta)  =  \displaystyle\int_{x \in \mathcal{X}(x_{obs})}   \exp(\ell _{x} (\theta|x_{obs})) dx 
	\label{logy}
\end{equation}

This integration is usually impossible to compute in practice for most diversification models (\ref{logy}). We can obtain a numerical approximation by using the Monte-Carlo approach considering 

\begin{eqnarray} 
	f (x_{obs}|\theta) &=& \displaystyle\int_{x \in \mathcal{X}(x_{obs})} f (x|\theta) dx \nonumber \\ 
	&=&\displaystyle\int_{x \in \mathcal{X}(x_{obs})} \frac{f (x|\theta)}{f_m (x|\theta,x_{obs})} f_m (x|\theta,x_{obs}) dx \nonumber \\ 
	&\approx& \frac{1}{M}\sum_{x_i \sim f_m (x|\theta,x_{obs}) } \frac{f (x_i|\theta)}{f_m (x_i|\theta,x_{obs})} 
	\label{MC}
\end{eqnarray}
for $f (x|\theta) = \exp(\ell _{x} (\theta|x_{obs}))$, $M$ the Monte-Carlo sample size and $f_m$ is an arbitrary sampler of the missing part of the full tree given an extant tree $x_{obs}$. Our statistical framework is a generalisation of that of, which makes use of an Expectation-Maximization algorithm for maximising the likelihood

```{r}
time = proc.time()
# Example parameter set
pars <- c(mu = 0.1, lambda_0 = 0.5, beta_N = -0.01, beta_P = 0.01)
max_t <- 10
max_lin <- 1e5
max_tries <- 100

tree = emphasis:::sim_tree_pd_cpp(pars, max_t, max_lin, max_tries)

phylo = tree$tes
  
plot(phylo)


mu_interval <- c(0, 0.5)
lambda_interval <- c(0.3, 2)
betaN_interval <- c(-0.1, 0) 
betaP_interval <- c(-0.1, 0.1) 
max_lin = 100000

n_trees = 1000000
# Call the function
results <- AugmentMultiplePhyloPD(phylo = phylo,
                                  n_trees = n_trees,
                                  mu_interval = mu_interval,
                                  lambda_interval = lambda_interval,
                                  betaN_interval = betaN_interval,
                                  betaP_interval =betaP_interval,
                                  max_lin = max_lin,
                                  max_tries = max_tries)
print(proc.time()-time)
```


```{r}

trees_from_results <- results$trees
param_from_results <- results$param
rejected_overruns_from_results <- unlist(results$rejected_overruns)


rejected_lambda_from_results <- unlist(results$rejected_lambda)

rejected_zero_weights_from_results <- unlist(results$rejected_zero_weights)


times_from_results <- results$times
loglik_estimation_from_results <- as.numeric(unlist(results$loglik_estimation))
logf_from_results <- as.numeric(unlist(results$logf))
logg_from_results <- as.numeric(unlist(results$logg))


# Further analysis can be done using the 'results' list.
wi = !is.na(loglik_estimation_from_results)
dat = data.frame(srv=loglik_estimation_from_results[wi],
                  p1=param_from_results$mu[wi],
                  p2=param_from_results$lambda[wi],
                  p3=param_from_results$betaN[wi],
                  p4=param_from_results$betaP[wi],
                  rzw = rejected_zero_weights_from_results[wi],
                  rl = rejected_lambda_from_results[wi],
                  ro = rejected_overruns_from_results[wi])


#library(ggplot2)
#ggplot(dat) + geom_point(aes(x=p1,y=p2,colour=srv)) + theme_minimal()
#ggplot(dat) + geom_point(aes(x=p3,y=p4,colour=srv)) + theme_minimal()

#ggplot(dat) + geom_point(aes(x=p1,y=p2,colour=rzw)) + theme_minimal()
#ggplot(dat) + geom_point(aes(x=p3,y=p4,colour=rzw)) + theme_minimal()

#ggplot(dat) + geom_point(aes(x=p1,y=p2,colour=rl)) + theme_minimal()
#ggplot(dat) + geom_point(aes(x=p3,y=p4,colour=rl)) + theme_minimal()

#ggplot(dat) + geom_point(aes(x=p1,y=p2,colour=ro)) + theme_minimal()
#ggplot(dat) + geom_point(aes(x=p3,y=p4,colour=ro)) + theme_minimal()


gam_loglik_pd = mgcv::gam(srv~s(p1)+s(p3)+s(p2)+s(p4),data=dat)

summary(gam_loglik_pd)

```




## GAM 

One option to estimate the full function is to use Generalized Additive Models. 



```{r}

```

# Statistical learning 



### Likelihood function 

### Conditioning 

## MCEM 

## DE 

## GMM 